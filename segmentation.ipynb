{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from mmseg.apis import inference_model, init_model\n",
    "import warnings\n",
    "\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "config_file: str = \"pretrained_models/segformer_mit-b4_8xb2-160k_ade20k-512x512.py\"\n",
    "checkpoint_file: str = (\n",
    "    \"pretrained_models/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\"\n",
    ")\n",
    "\n",
    "img = \"demo_img/0000007.jpg\"\n",
    "save_dir = \"outputs/test\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model(config_file, checkpoint_file, device=\"cuda:0\")\n",
    "result = inference_model(model, img)\n",
    "# append img name to save_dir\n",
    "out_file = os.path.join(save_dir, img.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.inference import Segmentor\n",
    "\n",
    "Segmentor = Segmentor(config_file, checkpoint_file, device=\"cuda:0\")\n",
    "Segmentor.inference(img, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mmcv.imread(img, channel_order=\"rgb\")\n",
    "classes = Segmentor.ade_classes()\n",
    "dynamic_classes = Segmentor.dynamic_classes()\n",
    "num_classes = len(classes)\n",
    "sem_seg = result.pred_sem_seg.cpu().data\n",
    "print(sem_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape of image: {image.shape}\")\n",
    "print(f\"shape of sem_seg: {sem_seg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.unique(sem_seg)[::-1]\n",
    "legal_indices = ids < num_classes\n",
    "ids = ids[legal_indices]\n",
    "print(f\"ids: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select those not in dynamic classes\n",
    "ids = np.array([id for id in ids if id not in dynamic_classes])\n",
    "print(f\"ids: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_center_loc(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Get semantic seg center coordinate.\n",
    "\n",
    "    Args:\n",
    "        mask: np.ndarray: get from sem_seg\n",
    "    \"\"\"\n",
    "    loc = np.argwhere(mask == 1)\n",
    "\n",
    "    loc_sort = np.array(sorted(loc.tolist(), key=lambda row: (row[0], row[1])))\n",
    "    y_list = loc_sort[:, 0]\n",
    "    unique, indices, counts = np.unique(y_list, return_index=True, return_counts=True)\n",
    "    y_loc = unique[counts.argmax()]\n",
    "    y_most_freq_loc = loc[loc_sort[:, 0] == y_loc]\n",
    "    center_num = len(y_most_freq_loc) // 2\n",
    "    x = y_most_freq_loc[center_num][1]\n",
    "    y = y_most_freq_loc[center_num][0]\n",
    "    return np.array([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "alpha = 0.5\n",
    "labels = np.array(ids, dtype=np.int64)\n",
    "palette = Segmentor.ade_palette()\n",
    "colors = [palette[label] for label in labels]\n",
    "\n",
    "mask = np.zeros_like(image, dtype=np.uint8)\n",
    "for label, color in zip(labels, colors):\n",
    "    mask[sem_seg[0] == label, :] = color\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# (0,1] to change the size of the text relative to the image\n",
    "scale = 0.05\n",
    "fontScale = min(image.shape[0], image.shape[1]) / (25 / scale)\n",
    "fontColor = (255, 255, 255)\n",
    "if image.shape[0] < 300 or image.shape[1] < 300:\n",
    "    thickness = 1\n",
    "    rectangleThickness = 1\n",
    "else:\n",
    "    thickness = 2\n",
    "    rectangleThickness = 2\n",
    "lineType = 2\n",
    "\n",
    "if isinstance(sem_seg[0], torch.Tensor):\n",
    "    masks = sem_seg[0].numpy() == labels[:, None, None]\n",
    "else:\n",
    "    masks = sem_seg[0] == labels[:, None, None]\n",
    "masks = masks.astype(np.uint8)\n",
    "for mask_num in range(len(labels)):\n",
    "    classes_id = labels[mask_num]\n",
    "    classes_color = colors[mask_num]\n",
    "    loc = _get_center_loc(masks[mask_num])\n",
    "    text = classes[classes_id]\n",
    "    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "        text, font, fontScale, thickness\n",
    "    )\n",
    "    mask = cv2.rectangle(\n",
    "        mask,\n",
    "        loc,\n",
    "        (loc[0] + label_width + baseline, loc[1] + label_height + baseline),\n",
    "        classes_color,\n",
    "        -1,\n",
    "    )\n",
    "    mask = cv2.rectangle(\n",
    "        mask,\n",
    "        loc,\n",
    "        (loc[0] + label_width + baseline, loc[1] + label_height + baseline),\n",
    "        (0, 0, 0),\n",
    "        rectangleThickness,\n",
    "    )\n",
    "    mask = cv2.putText(\n",
    "        mask,\n",
    "        text,\n",
    "        (loc[0], loc[1] + label_height),\n",
    "        font,\n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        thickness,\n",
    "        lineType,\n",
    "    )\n",
    "color_seg = (image * (1 - alpha) + mask * alpha).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmcv.imwrite(mmcv.rgb2bgr(color_seg), out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atten_patch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
