{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from mmseg.models import BaseSegmentor\n",
    "from mmengine.structures import PixelData\n",
    "from mmseg.structures import SegDataSample\n",
    "from mmseg.apis import inference_model, init_model\n",
    "import warnings\n",
    "\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "config_file: str = \"pretrained_models/segformer_mit-b4_8xb2-160k_ade20k-512x512.py\"\n",
    "checkpoint_file: str = \"pretrained_models/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\"\n",
    "\n",
    "img = \"demo_img/0000007.jpg\"\n",
    "save_dir = \"outputs/test\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/run/.miniconda3/envs/atten_patch/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/run/.miniconda3/envs/atten_patch/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: pretrained_models/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\n"
     ]
    }
   ],
   "source": [
    "model = init_model(config_file, checkpoint_file, device=\"cuda:0\")\n",
    "result = inference_model(model, img)\n",
    "# append img name to save_dir\n",
    "out_file = os.path.join(save_dir, img.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[43, 43, 43,  ...,  2,  2,  2],\n",
      "         [43, 43, 43,  ...,  2,  2,  2],\n",
      "         [43, 43, 43,  ...,  2,  2,  2],\n",
      "         ...,\n",
      "         [ 6,  6,  6,  ...,  6,  6,  6],\n",
      "         [ 6,  6,  6,  ...,  6,  6,  6],\n",
      "         [ 6,  6,  6,  ...,  6,  6,  6]]])\n"
     ]
    }
   ],
   "source": [
    "from segmentation.inference import Segmentor\n",
    "\n",
    "image = mmcv.imread(img, channel_order='rgb')\n",
    "classes = Segmentor.ade_classes()\n",
    "dynamic_classes = Segmentor.dynamic_classes()\n",
    "num_classes = len(classes)\n",
    "sem_seg = result.pred_sem_seg.cpu().data\n",
    "print(sem_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image: (240, 352, 3)\n",
      "shape of sem_seg: torch.Size([1, 240, 352])\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of image: {image.shape}\")\n",
    "print(f\"shape of sem_seg: {sem_seg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [83 43 32 29  6  4  2  0]\n"
     ]
    }
   ],
   "source": [
    "ids = np.unique(sem_seg)[::-1]\n",
    "legal_indices = ids < num_classes\n",
    "ids = ids[legal_indices]\n",
    "print(f\"ids: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [32 29  6  4  0]\n"
     ]
    }
   ],
   "source": [
    "# select those not in dynamic classes\n",
    "ids = np.array([id for id in ids if id not in dynamic_classes])\n",
    "print(f\"ids: {ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_center_loc(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Get semantic seg center coordinate.\n",
    "\n",
    "    Args:\n",
    "        mask: np.ndarray: get from sem_seg\n",
    "    \"\"\"\n",
    "    loc = np.argwhere(mask == 1)\n",
    "\n",
    "    loc_sort = np.array(\n",
    "        sorted(loc.tolist(), key=lambda row: (row[0], row[1])))\n",
    "    y_list = loc_sort[:, 0]\n",
    "    unique, indices, counts = np.unique(\n",
    "        y_list, return_index=True, return_counts=True)\n",
    "    y_loc = unique[counts.argmax()]\n",
    "    y_most_freq_loc = loc[loc_sort[:, 0] == y_loc]\n",
    "    center_num = len(y_most_freq_loc) // 2\n",
    "    x = y_most_freq_loc[center_num][1]\n",
    "    y = y_most_freq_loc[center_num][0]\n",
    "    return np.array([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "alpha = 0.5\n",
    "labels = np.array(ids, dtype=np.int64)\n",
    "palette = Segmentor.ade_palette()\n",
    "colors = [palette[label] for label in labels]\n",
    "\n",
    "mask = np.zeros_like(image, dtype=np.uint8)\n",
    "for label, color in zip(labels, colors):\n",
    "    mask[sem_seg[0] == label, :] = color\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# (0,1] to change the size of the text relative to the image\n",
    "scale = 0.05\n",
    "fontScale = min(image.shape[0], image.shape[1]) / (25 / scale)\n",
    "fontColor = (255, 255, 255)\n",
    "if image.shape[0] < 300 or image.shape[1] < 300:\n",
    "    thickness = 1\n",
    "    rectangleThickness = 1\n",
    "else:\n",
    "    thickness = 2\n",
    "    rectangleThickness = 2\n",
    "lineType = 2\n",
    "\n",
    "if isinstance(sem_seg[0], torch.Tensor):\n",
    "    masks = sem_seg[0].numpy() == labels[:, None, None]\n",
    "else:\n",
    "    masks = sem_seg[0] == labels[:, None, None]\n",
    "masks = masks.astype(np.uint8)\n",
    "for mask_num in range(len(labels)):\n",
    "    classes_id = labels[mask_num]\n",
    "    classes_color = colors[mask_num]\n",
    "    loc = _get_center_loc(masks[mask_num])\n",
    "    text = classes[classes_id]\n",
    "    (label_width, label_height), baseline = cv2.getTextSize(\n",
    "        text, font, fontScale, thickness)\n",
    "    mask = cv2.rectangle(mask, loc,\n",
    "                            (loc[0] + label_width + baseline,\n",
    "                            loc[1] + label_height + baseline),\n",
    "                            classes_color, -1)\n",
    "    mask = cv2.rectangle(mask, loc,\n",
    "                            (loc[0] + label_width + baseline,\n",
    "                            loc[1] + label_height + baseline),\n",
    "                            (0, 0, 0), rectangleThickness)\n",
    "    mask = cv2.putText(mask, text, (loc[0], loc[1] + label_height),\n",
    "                        font, fontScale, fontColor, thickness,\n",
    "                        lineType)\n",
    "color_seg = (image * (1 - alpha) + mask * alpha).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmcv.imwrite(mmcv.rgb2bgr(color_seg), out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atten_patch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
