{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from superpoint.superpoint import SuperPointFrontend\n",
    "from superpoint.utils import get_query_img_name, get_refer_img_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read failed cases from specific file saved by pickle.dump()\n",
    "with open('config/eval_config.yaml', 'r') as fin:\n",
    "    config = yaml.safe_load(fin)\n",
    "\n",
    "DATASET = config[\"dataset\"][\"name\"]\n",
    "ATTEN_PATH = config[\"results_path\"] + DATASET + \"/\" + config[\"output_1\"][\"method\"] + \"/\" + config[\"output_1\"][\"anchor_select_policy\"] + \"/failed_cases\"\n",
    "FULL_GEO_PATH = config[\"results_path\"] + DATASET + \"/\" + config[\"output_2\"][\"method\"] + \"/\" + config[\"output_2\"][\"anchor_select_policy\"] + \"/failed_cases\"\n",
    "\n",
    "def read_failed_cases(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        failed_cases = pickle.load(f)\n",
    "    return failed_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the filed cases for attention patch\n",
    "atten_failed_cases = read_failed_cases(ATTEN_PATH)\n",
    "\n",
    "# read the filed cases for attention patch\n",
    "all_failed_cases = read_failed_cases(FULL_GEO_PATH)\n",
    "\n",
    "print(f\"The number of failed cases in atten patch is {len(atten_failed_cases)}\")\n",
    "print(f\"The number of failed cases in cross match is {len(all_failed_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PATH = config[\"dataset\"][\"Root\"] + config[\"dataset\"][\"query_dir\"]\n",
    "REF_PATH = config[\"dataset\"][\"Root\"] + config[\"dataset\"][\"refer_dir\"]\n",
    "\n",
    "# get the images of failed cases\n",
    "def get_failed_images(failed_cases, query_path, ref_path):\n",
    "    query_images = []\n",
    "    wrong_pred = []\n",
    "    ref_images = []\n",
    "    for case in failed_cases:\n",
    "        # the image name is in 7 digits and in the format of .jpg\n",
    "        query_images.append(os.path.join(query_path, str(case[0]).zfill(7) + '.jpg'))\n",
    "        wrong_pred.append(os.path.join(query_path, str(case[1]).zfill(7) + '.jpg'))\n",
    "        ref_images.append(os.path.join(ref_path, str(case[2][0]).zfill(7) + '.jpg'))\n",
    "    return query_images, wrong_pred, ref_images\n",
    "\n",
    "def display_failed_images(failed_cases):\n",
    "    query_images, wrong_pred, ref_images = get_failed_images(failed_cases, QUERY_PATH, REF_PATH)\n",
    "\n",
    "    labels = [\"query image\", \"wrong prediction\", \"reference image\"]\n",
    "\n",
    "    # display the images of failed cases\n",
    "    for i in range(len(query_images)):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        query_image = mpimg.imread(query_images[i])\n",
    "        wrong_pred_image = mpimg.imread(wrong_pred[i])\n",
    "        ref_image = mpimg.imread(ref_images[i])\n",
    "        axes[0].imshow(query_image)\n",
    "        axes[0].set_title(labels[0])\n",
    "        axes[1].imshow(wrong_pred_image)\n",
    "        axes[1].set_title(labels[1])\n",
    "        axes[2].imshow(ref_image)\n",
    "        axes[2].set_title(labels[2])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "# Plot the failed cases\n",
    "# display_failed_images(atten_failed_cases)\n",
    "# display_failed_images(all_failed_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the common and differences between all and atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetComparer:\n",
    "    def __init__(self, data1, data2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.common_queries = []\n",
    "        self.different_queries = []\n",
    "\n",
    "    def compare_datasets(self):\n",
    "        # Extract the query data from both datasets\n",
    "        queries1 = [item[0] for item in self.data1]\n",
    "        queries2 = [item[0] for item in self.data2]\n",
    "\n",
    "        # Find common queries\n",
    "        self.common_queries = list(set(queries1).intersection(queries2))\n",
    "\n",
    "        # Find different queries\n",
    "        self.different_queries = list(set(queries1).symmetric_difference(queries2))\n",
    "        \n",
    "        print(f\"The number of failed cases in common is {len(self.common_queries)}\")\n",
    "        print(f\"The number of failed cases in different is {len(self.different_queries)}\")\n",
    "\n",
    "    def are_wrong_predictions_same(self):\n",
    "        # Do the comparison if lists are empty\n",
    "        if not self.common_queries and not self.different_queries:\n",
    "            self.compare_datasets()\n",
    "        \n",
    "        # Initialize a dictionary to store the wrong predictions for common queries\n",
    "        wrong_preds_dict = {}\n",
    "\n",
    "        # Populate the dictionary with common queries and their corresponding wrong predictions\n",
    "        for query in self.common_queries:\n",
    "            wrong_preds_dict[query] = (self.find_wrong_prediction(self.data1, query),\n",
    "                                       self.find_wrong_prediction(self.data2, query))\n",
    "\n",
    "        # Check if wrong predictions are the same for common queries\n",
    "        same_wrong_preds = {query: wrong_preds for query, wrong_preds in wrong_preds_dict.items() if\n",
    "                            wrong_preds[0] == wrong_preds[1]}\n",
    "\n",
    "        return same_wrong_preds\n",
    "\n",
    "    def find_wrong_prediction(self, data, query):\n",
    "        for item in data:\n",
    "            if item[0] == query:\n",
    "                return item[1]\n",
    "        return None\n",
    "    \n",
    "    def find_data_for_different_queries(self):\n",
    "        different_queries = self.different_queries\n",
    "\n",
    "        # Initialize a list to store data for different queries in data1\n",
    "        different_data_in_data1 = []\n",
    "\n",
    "        # Find data associated with different queries in data1\n",
    "        for query in different_queries:\n",
    "            for item in self.data1:\n",
    "                if item[0] == query:\n",
    "                    different_data_in_data1.append(item)\n",
    "\n",
    "        return different_data_in_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparer = DatasetComparer(atten_failed_cases, all_failed_cases)\n",
    "comparer.compare_datasets()\n",
    "same_wrong_preds = comparer.are_wrong_predictions_same()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_data_atten = comparer.find_data_for_different_queries()\n",
    "different_data_atten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of the attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.55\n",
    "reproj_err = 3\n",
    "params = [threshold, reproj_err]\n",
    "method = 'AttnPatch'\n",
    "\n",
    "query_index_offset = 0\n",
    "refer_index_offset = 0\n",
    "\n",
    "query_descriptors = []\n",
    "refer_descriptors = []\n",
    "wrong_pred_descriptors = []\n",
    "query_anchors = []\n",
    "\n",
    "query_rgbs = []\n",
    "refer_rgbs = []\n",
    "wrong_pred_rgbs = []\n",
    "\n",
    "pos_ptr = np.array([[-99, -98, -97, -96, -95, -94, -93],\n",
    "                    [-67, -66, -65, -64, -63, -62, -61],\n",
    "                    [-35, -34, -33, -32, -31, -30, -29],\n",
    "                    [-3, -2, -1, 0, 1, 2, 3],\n",
    "                    [29, 30, 31, 32, 33, 34, 35],\n",
    "                    [61, 62, 63, 64, 65, 66, 67],\n",
    "                    [93, 94, 95, 96, 97, 98, 99]])\n",
    "\n",
    "idx_table = np.reshape(np.array([val for val in range(0, 32 * 32)]), (32, 32))\n",
    "cache_table = np.zeros((1024, 2), dtype=int)\n",
    "for cnt in range(1024):\n",
    "    ridx = int(cnt / 32)\n",
    "    cidx = int(cnt % 32)\n",
    "    cache_table[cnt] = np.array([ridx, cidx])\n",
    "\n",
    "# Stub to warn about opencv version.\n",
    "if int(cv2.__version__[0]) < 3:  # pragma: no cover\n",
    "    print('Warning: OpenCV 3 is not installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==> Loading pre-trained network...\")\n",
    "fe = SuperPointFrontend(weights_path=config[\"model\"][\"weights_path\"],\n",
    "                        nms_dist=config[\"model\"][\"nms_dist\"],\n",
    "                        conf_thresh=config[\"model\"][\"conf_thresh\"],\n",
    "                        nn_thresh=config[\"model\"][\"nn_thresh\"],\n",
    "                        cuda=config[\"model\"][\"cuda\"])\n",
    "\n",
    "print(\"===> Successfully loaded pre-trained network.\")\n",
    "\n",
    "for i in tqdm(range(len(different_data_atten))):\n",
    "    # print('==> Refer: ' + str(refer + refer_index_offset))\n",
    "    try:\n",
    "        refer_img = cv2.imread(REF_PATH + '/' + get_refer_img_name(\"SPED\", different_data_atten[i][2][0]))\n",
    "        query_img = cv2.imread(QUERY_PATH + '/' + get_query_img_name(\"SPED\", different_data_atten[i][0]))\n",
    "        wrong_pred_img = cv2.imread(REF_PATH + '/' + get_query_img_name(\"SPED\", different_data_atten[i][1]))\n",
    "\n",
    "    except(IOError, ValueError) as e:\n",
    "        refer_img = None\n",
    "        print('Exception! \\n \\n \\n \\n')\n",
    "\n",
    "    refer_img = cv2.resize(refer_img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    refer_img = (refer_img.astype('float32') / 255.)\n",
    "    refer_img = cv2.cvtColor(refer_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # for query and wrong prediction\n",
    "    query_img = cv2.resize(query_img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    query_img = (query_img.astype('float32') / 255.)\n",
    "    query_img = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    wrong_pred_img = cv2.resize(wrong_pred_img, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    wrong_pred_img = (wrong_pred_img.astype('float32') / 255.)\n",
    "    wrong_pred_img = cv2.cvtColor(wrong_pred_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    desc = fe.run(refer_img)\n",
    "    refer_descriptors.append(desc)\n",
    "    \n",
    "    # anchors\n",
    "    anchors = np.array([], dtype=int)\n",
    "    query_self_sim = np.dot(desc.transpose(), desc)\n",
    "    query_self_sim = np.sum(query_self_sim, axis=0)\n",
    "    query_self_sim = np.reshape(query_self_sim, (32, 32))\n",
    "    \n",
    "    for row in range(8):\n",
    "        for col in range(8):\n",
    "            pos = np.argmin(query_self_sim[(4 * row):(4 * (row + 1)), (4 * col):(4 * (col + 1))])\n",
    "            tmp_anchor = np.reshape(idx_table[(4 * row):(4 * (row + 1)), (4 * col):(4 * (col + 1))], -1)[pos]\n",
    "            anchors = np.append(anchors, tmp_anchor)\n",
    "            \n",
    "    query_anchors.append(anchors)\n",
    "    \n",
    "    desc = fe.run(query_img)\n",
    "    query_descriptors.append(desc)\n",
    "    \n",
    "    desc = fe.run(wrong_pred_img)\n",
    "    wrong_pred_descriptors.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention patch visualization\n",
    "def visual_atten(query_descriptor_in, refer_descriptor_in, anchors_in, idx, is_refer):\n",
    "    score_matrix = np.dot(query_descriptor_in.transpose()[anchors_in],\n",
    "                                      refer_descriptor_in)\n",
    "    score_max_vector = np.max(score_matrix, axis=1)\n",
    "    where_max_matrix = np.argmax(score_matrix, axis=1)\n",
    "\n",
    "    where = [idx for idx, val in enumerate(score_max_vector) if val > threshold]\n",
    "    query_where = anchors_in[where]\n",
    "    refer_where = where_max_matrix[where]\n",
    "\n",
    "    query_pos = np.array([], dtype=int)\n",
    "    refer_pos = np.array([], dtype=int)\n",
    "\n",
    "    for cnt in range(query_where.shape[0]):\n",
    "        query_pos = np.append(query_pos, query_where[cnt] + pos_ptr)\n",
    "        refer_pos = np.append(refer_pos, refer_where[cnt] + pos_ptr)\n",
    "\n",
    "    qpos_idx = np.where(query_pos >= 0)\n",
    "    query_pos = query_pos[qpos_idx]\n",
    "    refer_pos = refer_pos[qpos_idx]\n",
    "    qpos_idx = np.where(query_pos < 1023)\n",
    "    query_pos = query_pos[qpos_idx]\n",
    "    refer_pos = refer_pos[qpos_idx]\n",
    "    rpos_idx = np.where(refer_pos >= 0)\n",
    "    query_pos = query_pos[rpos_idx]\n",
    "    refer_pos = refer_pos[rpos_idx]\n",
    "    rpos_idx = np.where(refer_pos < 1023)\n",
    "    query_pos = query_pos[rpos_idx]\n",
    "    refer_pos = refer_pos[rpos_idx]\n",
    "\n",
    "    query_roi = np.append(query_where, query_pos)\n",
    "    refer_roi = np.append(refer_where, refer_pos)\n",
    "\n",
    "    query_rois = query_descriptor_in.T[query_roi]\n",
    "    refer_rois = refer_descriptor_in.T[refer_roi]\n",
    "\n",
    "    mul_score = np.sum(np.multiply(query_rois, refer_rois), axis=1)\n",
    "    select_roi_idx = np.where(mul_score > threshold)\n",
    "    query_roi = query_roi[select_roi_idx]\n",
    "    refer_roi = refer_roi[select_roi_idx]\n",
    "    _, unique_indices, _, _ = np.unique(query_roi, return_index=True,\n",
    "                                        return_inverse=True,\n",
    "                                        return_counts=True)\n",
    "    query_roi = query_roi[unique_indices]\n",
    "    refer_roi = refer_roi[unique_indices]\n",
    "\n",
    "    query_2d_idx = cache_table[query_roi]\n",
    "    refer_2d_idx = cache_table[refer_roi]\n",
    "    \n",
    "    score = 0\n",
    "\n",
    "    if query_2d_idx.shape[0] > 3:\n",
    "        _, mask = cv2.findHomography(refer_2d_idx, query_2d_idx, cv2.FM_RANSAC,\n",
    "                                        ransacReprojThreshold=reproj_err)\n",
    "\n",
    "        inlier_index_keypoints = refer_2d_idx[mask.ravel() == 1]\n",
    "        inlier_count = inlier_index_keypoints.shape[0]\n",
    "        score = inlier_count / query_descriptor_in.shape[0]\n",
    "        \n",
    "    query_rgb = cv2.imread(QUERY_PATH + '/' + get_query_img_name(\"SPED\", different_data_atten[idx][0]))\n",
    "    \n",
    "    if is_refer:\n",
    "        refer_rgb = cv2.imread(REF_PATH + '/' + get_refer_img_name(\"SPED\", different_data_atten[idx][2][0]))\n",
    "    else:\n",
    "        refer_rgb = cv2.imread(QUERY_PATH + '/' + get_query_img_name(\"SPED\", different_data_atten[idx][1]))\n",
    "        \n",
    "    query_rgb = cv2.resize(query_rgb, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    query_rgb = (query_rgb.astype('float32') / 255.)\n",
    "    \n",
    "    refer_rgb = cv2.resize(refer_rgb, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "    refer_rgb = (refer_rgb.astype('float32') / 255.)\n",
    "    \n",
    "    \n",
    "    query_img_labels = cv2.cvtColor(query_rgb, cv2.COLOR_RGB2BGR)\n",
    "    refer_img_labels = cv2.cvtColor(refer_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for cnt in range(query_roi.shape[0]):\n",
    "        query_where_ = query_roi[cnt]\n",
    "        refer_where_ = refer_roi[cnt]\n",
    "\n",
    "        cv2.rectangle(query_img_labels,\n",
    "                        (int(query_where_ % 32)*8,\n",
    "                        int(query_where_/32)*8),\n",
    "                        ((int(query_where_ % 32)+1)*8,\n",
    "                        (int(query_where_/32)+1)*8),\n",
    "                        (0, 128, 0), 1)\n",
    "\n",
    "        cv2.rectangle(refer_img_labels,\n",
    "                        (int(refer_where_ % 32)*8,\n",
    "                        int(refer_where_/32)*8),\n",
    "                        ((int(refer_where_ % 32)+1)*8,\n",
    "                        (int(refer_where_/32)+1)*8),\n",
    "                        (0, 128, 0), 1)\n",
    "        \n",
    "    return query_img_labels, refer_img_labels, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(different_data_atten)):\n",
    "    \n",
    "    query_descriptor = query_descriptors[i]\n",
    "    refer_descriptor = refer_descriptors[i]\n",
    "    wrong_pred_descriptor = wrong_pred_descriptors[i]\n",
    "    \n",
    "    anchors = query_anchors[i]\n",
    "    \n",
    "    query_img_1, refer_q_img, score_1 = visual_atten(query_descriptor, refer_descriptor, anchors, i, True)\n",
    "    query_img_2, wrong_pred, score_2 = visual_atten(query_descriptor, wrong_pred_descriptor, anchors, i, False)\n",
    "    \n",
    "    print(f\"Score for query is {score_1}\")\n",
    "    print(f\"Score for wrong prediction is {score_2}\")\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "    # Set titles for each subplot\n",
    "    titles = [\"query\", \"reference\", \"query\", \"wrong prediction\"]\n",
    "    # Plot the subimages and set titles\n",
    "    \n",
    "    axs[0].imshow(query_img_1)\n",
    "    axs[0].set_title(titles[0])\n",
    "    axs[1].imshow(refer_q_img)\n",
    "    axs[1].set_title(titles[1])\n",
    "    axs[2].imshow(query_img_2)\n",
    "    axs[2].set_title(titles[2])\n",
    "    axs[3].imshow(wrong_pred)\n",
    "    axs[3].set_title(titles[3])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using edge detector to visualize the attention patch\n",
    "for case in atten_failed_cases:\n",
    "    # read query, wrong prediction and reference images\n",
    "    query_img = cv2.imread(QUERY_PATH + '/' + get_query_img_name(\"SPED\", case[0]))\n",
    "    wrong_pred_img = cv2.imread(REF_PATH + '/' + get_query_img_name(\"SPED\", case[1]))\n",
    "    refer_img = cv2.imread(REF_PATH + '/' + get_refer_img_name(\"SPED\", case[2][0]))\n",
    "    \n",
    "    # edge detection\n",
    "    edges_query = cv2.Canny(query_img, 300, 1000, apertureSize=5)\n",
    "    edges_wrong_pred = cv2.Canny(wrong_pred_img, 300, 1000, apertureSize=5)\n",
    "    edges_refer = cv2.Canny(refer_img, 300, 1000, apertureSize=5)\n",
    "    \n",
    "    # plot the images\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    # Set titles for each subplot\n",
    "    titles = [\"query\", \"wrong prediction\", \"reference\"]\n",
    "    # Plot the subimages and set titles\n",
    "    axs[0].imshow(edges_query)\n",
    "    axs[0].set_title(titles[0])\n",
    "    axs[1].imshow(edges_wrong_pred)\n",
    "    axs[1].set_title(titles[1])\n",
    "    axs[2].imshow(edges_refer)\n",
    "    axs[2].set_title(titles[2])\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust-point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
